"""
Phi√™n b·∫£n n√¢ng c·∫•p chuy√™n s√¢u cho trader gi·ªØ l·ªánh 1‚Äì6 gi·ªù.

T√≠nh nƒÉng ch√≠nh:
‚úÖ TP/SL th√¥ng minh theo swing
‚úÖ Ki·ªÉm tra RR ‚â• 1.2 v√† SL kh√¥ng qu√° h·∫πp
‚úÖ Volume spike x√°c nh·∫≠n t√≠n hi·ªáu top30
‚úÖ X√°c nh·∫≠n ƒëa chi·ªÅu RSI/EMA/MACD/ADX/Bollinger
‚úÖ Lo·∫°i b·ªè t√≠n hi·ªáu sideway (choppy filter)
‚úÖ M√¥ h√¨nh gi√°: Flag, Wedge, Head & Shoulders (d·∫°ng ƒë∆°n gi·∫£n)
‚úÖ Entry h·ª£p l·ªá n·∫øu n·∫±m trong v√πng Fibonacci retracement (0.5‚Äì0.618)
"""
# ==== STRUCTURED LOG HELPERS ====
import requests
import pandas as pd
import numpy as np
import time
import datetime as dt
import json
import os
import logging
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from pytz import timezone
import pytz
from datetime import datetime, timedelta
from datetime import timezone
from datetime import datetime, timezone
from datetime import datetime, timezone, timedelta
from contextlib import contextmanager
import sys, io, logging


DEBUG_BACKTEST = True
logger = logging.getLogger()
logger.setLevel(logging.INFO)  # lu√¥n b·∫≠t DEBUG/INFO
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
LOG_NAME = "SIGNAL"
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] [%(name)s] %(message)s")
logger = logging.getLogger(LOG_NAME)

def log_pass(stage: str, symbol: str, **kv):
    extras = " ".join(f"{k}={v}" for k,v in kv.items())
    logger.info(f"PASS|{stage}|{symbol}|{extras}")

def log_drop(stage: str, symbol: str, reason: str, **kv):
    extras = " ".join(f"{k}={v}" for k,v in kv.items())
    logger.info(f"DROP|{stage}|{symbol}|{reason} {extras}")

def drop_return():
    return None, None, None, None, False, None


# ========== C·∫§U H√åNH ==========
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
SHEET_CSV_URL = os.getenv("SHEET_CSV_URL")  # ƒê·∫∑t l·∫°i bi·∫øn n·∫øu ch∆∞a c√≥
# C·∫•u h√¨nh scope
scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# ƒê·ªçc file JSON credentials ƒë√£ upload l√™n Render (t√™n ph·∫£i l√† service_account.json)
creds = ServiceAccountCredentials.from_json_keyfile_name('/etc/secrets/service_account.json', scope)

# Authorize gspread
client = gspread.authorize(creds)

# K·∫øt n·ªëi ƒë·∫øn file Google Sheet
# ‚úÖ Th√™m 2 d√≤ng debug n√†y v√†o ngay sau khi t√°ch sheet_id
try:
    sheet_id = SHEET_CSV_URL.split("/d/")[1].split("/")[0]
    print(f"[DEBUG] sheet_id = {sheet_id}")
    sheet = client.open_by_key(sheet_id).worksheet("DATA_FUTURE")
    time.sleep(1)
    print("[DEBUG] ƒê√£ m·ªü sheet th√†nh c√¥ng.")
except Exception as e:
    print(f"[ERROR] Kh√¥ng m·ªü ƒë∆∞·ª£c sheet: {e}")
    raise

# ========== THAM S·ªê K·ª∏ THU·∫¨T ==========
TP_MULTIPLIER = 1.5
SL_MULTIPLIER = 1.0
ADX_THRESHOLD = 12
K_ATR_SL = 0.6   # t·ªëi thi·ªÉu SL = max(SL_MIN_PCT, 0.6*ATR/entry)
K_ATR_TP = 1.2   # t·ªëi thi·ªÉu TP = max(TP_MIN_{RELAX|STRICT}, 1.2*ATR/entry)
COINS_LIMIT = 300  # S·ªë coin ph√¢n t√≠ch m·ªói l∆∞·ª£t
# ===== CONFIG =====
SL_MIN_PCT   = 0.006    # SL t·ªëi thi·ªÉu 0.6%
TP_MIN_RELAX = 0.02     # TP t·ªëi thi·ªÉu 2% (RELAX)
TP_MIN_STRICT= 0.05     # TP t·ªëi thi·ªÉu 5% (STRICT)
TOPN_PER_BATCH = 10   # tu·ª≥ b·∫°n, 5/10/15...
SL_MIN_PCT_BASE = SL_MIN_PCT
TP_MIN_RELAX_BASE = TP_MIN_RELAX
TP_MIN_STRICT_BASE = TP_MIN_STRICT
WICK_RATIO_LIMIT = 0.8  # Ng∆∞·ª°ng % chi·ªÅu d√†i n·∫øn r√¢u, TB 0.5

# ========================== N√ÇNG C·∫§P CHUY√äN S√ÇU ==========================
# ====== PRESET & HELPERS ======

STRICT_CFG = {
    "VOLUME_PERCENTILE": 80,   # top 20%
    "ADX_MIN_15M": 22,
    "BBW_MIN": 0.013,
    "RR_MIN": 1.5, # RR t·ªëi thi·ªÉu
    "NEWS_BLACKOUT_MIN": 60,   # ph√∫t
    "ATR_CLEARANCE_MIN": 0.8,  # >= 0.8 ATR
    "USE_VWAP": True,
    "RELAX_EXCEPT": False,
    "TAG": "STRICT",
    "RSI_LONG_MIN": 55,
    "RSI_SHORT_MAX": 45,
    "RSI_1H_LONG_MIN": 50,
    "RSI_1H_SHORT_MAX": 50,
    "MACD_DIFF_LONG_MIN": 0.05,
    "MACD_DIFF_SHORT_MIN": 0.001,
    "ALLOW_1H_NEUTRAL": False,
    "REQUIRE_RETEST": True,
    "REQ_EMA200_MULTI": True,
}
RELAX_CFG = {
    "VOLUME_PERCENTILE": 40,   # top 60%
    "ADX_MIN_15M": 18,
    "BBW_MIN": 0.048,
    "RR_MIN": 1.0,
    "NEWS_BLACKOUT_MIN": 0, # ph√∫t
    "ATR_CLEARANCE_MIN": 0.6, # >= 0.7ART
    "USE_VWAP": True,
    "RELAX_EXCEPT": True,      # cho ph√©p ngo·∫°i l·ªá khi breakout + volume
    "TAG": "RELAX",
    "RSI_LONG_MIN": 45,
    "RSI_SHORT_MAX": 55,    # tƒÉng l√† l·ªèng
    "RSI_1H_LONG_MIN": 45,
    "RSI_1H_SHORT_MAX": 55,    # tƒÉng l√† l·ªèng
    "MACD_DIFF_LONG_MIN": 0.0003,
    "MACD_DIFF_SHORT_MIN": -0.0003,
    "ALLOW_1H_NEUTRAL": True,
    "REQUIRE_RETEST": False,
    "REQ_EMA200_MULTI": False,
    "SR_NEAR_K_ATR": 0.8,   # h·ªá s·ªë * ATR cho ƒë·ªô g·∫ßn (t·ª´ 0.6 ‚Üí 1.0 ho·∫∑c 1.2 ƒë·ªÉ tho√°ng)
    "SR_NEAR_PCT":   1.2, # 1.2% kho·∫£ng c√°ch tuy·ªát ƒë·ªëi (tu·ª≥)
    "EARLY_ALERT": True,            # b·∫≠t b√°o s·ªõm
    "EARLY_USE_CURRENT_BAR": True,  # d√πng n·∫øn ƒëang ch·∫°y (kh·ªèi ch·ªù ƒë√≥ng)
    "EARLY_RATING_PENALTY": 1       # tr·ª´ 1 sao n·∫øu l√† t√≠n hi·ªáu s·ªõm
}

# log 1 d√≤ng/coin/mode + t·∫Øt log t·∫°m th·ªùi

_logged_once = {}
def log_once(mode, symbol, msg, level="info"):
    key = (mode, symbol)
    if _logged_once.get(key): return
    _logged_once[key] = True
    getattr(logging, level)(msg)

def reset_log_once_for_mode(mode, symbols):
    for s in symbols:
        _logged_once.pop((mode, s), None)

@contextmanager
def mute_logs():
    prev = logging.getLogger().level
    logging.getLogger().setLevel(logging.WARNING)
    try: yield
    finally: logging.getLogger().setLevel(prev)

@contextmanager
def suppress_output():
    _stdout, _stderr = sys.stdout, sys.stderr
    sys.stdout, sys.stderr = io.StringIO(), io.StringIO()
    try: yield
    finally: sys.stdout, sys.stderr = _stdout, _stderr

# ====== News blackout ======
def load_news_events():
    import json, os, requests
    url = os.getenv("NEWS_JSON_URL","").strip()
    if url:
        try:
            r = requests.get(url, timeout=8)
            if r.ok: return r.json()
        except: pass
    path = os.getenv("NEWS_JSON_FILE","news_events.json")
    try:
        with open(path,"r") as f: return json.load(f)
    except: return []


def in_news_blackout(window_min: int):
    now = dt.datetime.now(timezone.utc)
    for e in load_news_events():
        t = e.get("time") or e.get("time_utc")
        if not t: continue
        try:
            if t.endswith("Z"): tt = datetime.fromisoformat(t.replace("Z","+00:00"))
            else: tt = datetime.fromisoformat(t)
        except: continue
        if abs((tt - now).total_seconds()) <= window_min*60:
            return True
    return False

# ====== VWAP + ATR clearance ======

def _atr(df, n=14):
    tr = np.maximum.reduce([
        (df["high"] - df["low"]).abs(),
        (df["high"] - df["close"].shift()).abs(),
        (df["low"] - df["close"].shift()).abs()
    ])
    tr = pd.Series(tr)  # ‚úÖ √âp v·ªÅ Series ƒë·ªÉ d√πng .rolling()
    return tr.rolling(n).mean()

def anchored_vwap(df, anchor_idx):
    sub = df.iloc[anchor_idx:]
    tp = (sub["high"] + sub["low"] + sub["close"]) / 3.0
    pv = (tp * sub["volume"]).cumsum()
    vv = sub["volume"].cumsum().replace(0, np.nan)
    vwap = pv / vv
    return float(vwap.iloc[-1])

def pick_anchor_index(df, side):
    win = df.iloc[-50:-5]
    return (win["low"].idxmin() if side=="LONG" else win["high"].idxmax())
def atr_clearance(df, side, mult):
    atr = float(_atr(df).iloc[-1])
    last = df.iloc[-1]
    z = df.iloc[-20:-1]
    if side=="LONG":
        obstacle = z["high"].max(); dist = obstacle - last["close"]
    else:
        obstacle = z["low"].min();  dist = last["close"] - obstacle
    if atr==0 or np.isnan(atr): return 0.0, False
    return dist/atr, (dist/atr) >= mult

def clean_missing_data(df, required_cols=["close", "high", "low", "volume"], max_missing=2):
    """N·∫øu thi·∫øu 1-2 gi√° tr·ªã, lo·∫°i b·ªè. N·∫øu thi·∫øu nhi·ªÅu h∆°n, tr·∫£ v·ªÅ None"""
    missing = df[required_cols].isnull().sum().sum()
    if missing > max_missing:
        return None
    return df.dropna(subset=required_cols)

def is_volume_spike(df):
    try:
        volumes = df["volume"].iloc[-20:]

        if len(volumes) < 10:
            logging.debug(f"[DEBUG][Volume FAIL] Kh√¥ng ƒë·ªß d·ªØ li·ªáu volume: ch·ªâ c√≥ {len(volumes)} n·∫øn")
            return False

        v_now = volumes.iloc[-1]
        threshold = np.percentile(volumes[:-1], 60) # TOP 40%

        if np.isnan(v_now) or np.isnan(threshold):
            logging.debug(f"[DEBUG][Volume FAIL] D·ªØ li·ªáu volume b·ªã NaN - v_now={v_now}, threshold={threshold}")
            return False

        logging.debug(f"[DEBUG][Volume Check] Volume hi·ªán t·∫°i = {v_now:.0f}, Threshold 60% = {threshold:.0f}")

        if v_now <= threshold:
            logging.debug(f"[DEBUG][Volume FAIL] Volume ch∆∞a ƒë·ªß spike")
            return False

        return True

    except Exception as e:
        logging.debug(f"[DEBUG][Volume FAIL] L·ªói khi ki·ªÉm tra volume: {e}")
        return False

def detect_breakout_pullback(df):
    df["ema20"] = df["close"].ewm(span=20).mean()
    recent_high = df["high"].iloc[-30:-10].max()
    ema = df["ema20"].iloc[-1]
    price = df["close"].iloc[-1]
    breakout = price > recent_high
    pullback = price < recent_high and price > ema
    return breakout and pullback

def find_support_resistance(df, window=30):
    highs = df["high"].iloc[-window:]
    lows = df["low"].iloc[-window:]
    return lows.min(), highs.max()

def rate_signal_strength(entry, sl, tp, short_trend, mid_trend):
    strength = 1
    if abs(tp - entry) / entry > 0.05:
        strength += 1
    if abs(entry - sl) / entry > 0.05:
        strength += 1
    if short_trend == mid_trend:
        strength += 1
    return "‚≠êÔ∏è" * min(strength, 5)

def _bt_row_key(coin: str, side: str, when_vn: str, mode: str) -> str:
    # Kh√≥a duy nh·∫•t cho 1 t√≠n hi·ªáu backtest
    return f"{coin.strip()}|{side.strip()}|{when_vn.strip()}|{mode.strip()}"

def load_existing_backtest_keys() -> set:
    """
    ƒê·ªçc sheet BACKTEST_RESULT v√† tr·∫£ v·ªÅ set c√°c key ƒë√£ t·ªìn t·∫°i
    C·ªôt: 0=Coin, 1=Side, 7=Ng√†y(VN), 8=Mode
    """
    try:
        rows = read_sheet_values("BACKTEST_RESULT") or []   # d√πng h√†m ƒë·ªçc sheet s·∫µn c√≥ c·ªßa b·∫°n
    except Exception:
        rows = []
    keys = set()
    for r in rows[0:]:  # b·ªè header
        if len(r) >= 9:
            coin  = str(r[0])
            side  = str(r[1])
            when_ = str(r[7])
            mode  = str(r[8])
            keys.add(_bt_row_key(coin, side, when_, mode))
    return keys

def ts_to_str(ms_or_s):
    try:
        tz = pytz.timezone("Asia/Ho_Chi_Minh")
        if ms_or_s > 10**12:  # nano
            ms_or_s = ms_or_s / 10**6
        if ms_or_s > 10**10:  # mili
            dt_obj = dt.datetime.utcfromtimestamp(ms_or_s/1000.0)
        else:
            dt_obj = dt.datetime.utcfromtimestamp(ms_or_s)
        return tz.fromutc(dt_obj).strftime("%d/%m/%Y %H:%M")
    except Exception:
        return str(ms_or_s)
        
def _pivots(series: pd.Series, lookback=30, win=3):
    """T√¨m 2 pivot highs & 2 pivot lows g·∫ßn nh·∫•t trong lookback n·∫øn (win = c·ª≠a s·ªï local-extrema)."""
    s = series.tail(lookback).reset_index(drop=True)
    n = len(s)
    if n < win*2+3:
        return None, None, None, None  # thi·∫øu d·ªØ li·ªáu
    # pivot high: s[i] l√† max trong [i-win, i+win]
    ph_idx = []
    pl_idx = []
    for i in range(win, n-win):
        seg = s[i-win:i+win+1]
        if s[i] == seg.max(): ph_idx.append(i)
        if s[i] == seg.min(): pl_idx.append(i)
    # l·∫•y 2 c√°i g·∫ßn nh·∫•t
    ph_idx = ph_idx[-2:] if len(ph_idx) >= 2 else (ph_idx if ph_idx else [])
    pl_idx = pl_idx[-2:] if len(pl_idx) >= 2 else (pl_idx if pl_idx else [])
    def _vals(idx_list):
        if len(idx_list) >= 2:
            return (idx_list[-2], s.iloc[idx_list[-2]]), (idx_list[-1], s.iloc[idx_list[-1]])
        return (None, None), (None, None)
    (i1h,v1h),(i2h,v2h) = _vals(ph_idx)
    (i1l,v1l),(i2l,v2l) = _vals(pl_idx)
    return (i1h, v1h, i2h, v2h, i1l, v1l, i2l, v2l)

def is_bear_div(price: pd.Series, osc: pd.Series, lb=30, win=3) -> bool:
    """Bearish divergence: price HH nh∆∞ng oscillator LH (veto LONG)."""
    if price is None or osc is None or len(price) < lb+5 or len(osc) < lb+5:
        return False
    i1h, p1h, i2h, p2h, *_ = _pivots(price, lb, win)
    _,  o1h, _,  o2h, *_ = _pivots(osc,   lb, win)
    if None in (i1h, p1h, i2h, p2h, o1h, o2h):
        return False
    # i1h < i2h ƒë·∫£m b·∫£o tr·∫≠t t·ª± th·ªùi gian
    return (i1h < i2h) and (p2h > p1h) and (o2h < o1h)

def is_bull_div(price: pd.Series, osc: pd.Series, lb=30, win=3) -> bool:
    """Bullish divergence: price LL nh∆∞ng oscillator HL (veto SHORT)."""
    if price is None or osc is None or len(price) < lb+5 or len(osc) < lb+5:
        return False
    *_, i1l, p1l, i2l, p2l = _pivots(price, lb, win)
    *_, o1l, o1v, o2l, o2v = _pivots(osc,   lb, win)
    if None in (i1l, p1l, i2l, p2l, o1l, o1v, o2l, o2v):
        return False
    return (i1l < i2l) and (p2l < p1l) and (o2v > o1v)

def _safe_dt(ts):
    """ts c√≥ th·ªÉ l√† ms ho·∫∑c s; tr·∫£ v·ªÅ datetime VN ho·∫∑c None."""
    try:
        import pandas as pd, pytz
        if ts is None: 
            return None
        ts = float(ts)
        if not (ts > 0):
            return None
        unit = 'ms' if ts > 1e12 else 's'  # ng∆∞·ª°ng th√¥: ms ~ 1e13, s ~ 1e9
        dt_utc = pd.to_datetime(ts, unit=unit, utc=True)
        return dt_utc.tz_convert('Asia/Ho_Chi_Minh')
    except Exception:
        return None
        
def fetch_ohlcv_okx(symbol: str, timeframe: str = "15m", limit: int = 1000):
    """
    Tr·∫£ DataFrame c·ªôt: timestamp(ms), open, high, low, close, volume
    OKX tr·∫£ data m·ªõi ‚Üí c≈©, timestamp l√† mili‚Äëgi√¢y (string).
    """
    import requests, pandas as pd
    from datetime import datetime

    try:
        # Map alias timeframe v·ªÅ format OKX
        timeframe_map = {
            "1h": "1H", "4h": "4H", "1d": "1D",
            "15m": "15m", "5m": "5m", "1m": "1m"
        }
        tf_in = timeframe
        timeframe = timeframe_map.get(timeframe.lower(), timeframe)
        logging.debug(f"üïí Timeframe input: {tf_in} => OKX d√πng: {timeframe}")

        if timeframe not in ("1m","5m","15m","30m","1H","4H","1D"):
            logging.warning(f"‚ö†Ô∏è Timeframe kh√¥ng h·ª£p l·ªá: {timeframe}")
            return None

        # OKX instId: BTC-USDT ‚Üí BTC-USDT-SWAP (n·∫øu thi·∫øu -SWAP)
        inst_id = symbol.upper().replace("/", "-")
        if not inst_id.endswith("-SWAP"):
            inst_id += "-SWAP"

        url = "https://www.okx.com/api/v5/market/candles"
        params = {"instId": inst_id, "bar": timeframe, "limit": limit}
        logging.debug(f"üåê G·ª≠i request n·∫øn OKX: instId={inst_id}, bar={timeframe}, limit={limit}")
        r = requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        js = r.json()
        data = js.get("data", []) or []
        
        # Parse: [ts, o, h, l, c, vol]
        rows = []
        for it in data:
            ts = int(it[0]) if it and it[0] is not None else 0
            o, h, l, c = it[1], it[2], it[3], it[4]
            vol = it[5] if len(it) > 5 else None
            rows.append([ts, o, h, l, c, vol])
        
        df = pd.DataFrame(rows, columns=["timestamp","open","high","low","close","volume"])
        
        # √âp ki·ªÉu chu·∫©n
        df["timestamp"] = pd.to_numeric(df["timestamp"], errors="coerce")  # ms ho·∫∑c s
        for col in ("open","high","low","close","volume"):
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        # N·∫øu timestamp ƒëang l√† GI√ÇY th√¨ ƒë·ªïi sang MILLISECOND
        if df["timestamp"].notna().any() and df["timestamp"].max() < 10**12:
            df["timestamp"] = df["timestamp"] * 1000.0
        
        # Lo·∫°i r·ªóng + sort
        df = df.dropna(subset=["timestamp","open","high","low","close"]).copy()
        df = df.sort_values("timestamp").reset_index(drop=True)
        
        # (t√πy) log ph·∫°m vi: ch·ªâ d√πng /1000 khi log, KH√îNG convert n·∫øu NaN
        if len(df):
            t0 = int(df["timestamp"].iloc[0]); t1 = int(df["timestamp"].iloc[-1])
            from datetime import datetime, timezone
            logging.debug(f"[BT] RAW {symbol}: "
                          f"[{datetime.fromtimestamp(t0/1000, tz=timezone.utc)} -> "
                          f"{datetime.fromtimestamp(t1/1000, tz=timezone.utc)}] | rows={len(df)}")
        else:
            logging.debug(f"[BT] RAW {symbol}: d·ªØ li·ªáu tr·ªëng.")
        
        return df

    except Exception as e:
        logging.warning(f"[OKX] fetch_ohlcv_okx l·ªói v·ªõi {symbol}: {e}")
        return None

def _ensure_ohlc(df):
    need = {"open","high","low","close"}
    if not need.issubset(set(df.columns)): 
        raise ValueError("Thi·∫øu c·ªôt OHLC")
    return df.dropna()

def _dmi_adx(df, n=14):
    """Tr·∫£ v·ªÅ Series: +DI, -DI, ADX (0..100). N·∫øu ƒë√£ c√≥ c·ªôt adx/plus_di/minus_di th√¨ d√πng lu√¥n."""
    d = _ensure_ohlc(df).copy()
    if {"adx","plus_di","minus_di"}.issubset(d.columns):
        return d["plus_di"], d["minus_di"], d["adx"]

    high, low, close = d["high"], d["low"], d["close"]
    up_move   = high.diff()
    down_move = -low.diff()

    plus_dm  = np.where((up_move > down_move) & (up_move > 0),  up_move, 0.0)
    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)

    tr1 = (high - low)
    tr2 = (high - close.shift()).abs()
    tr3 = (low  - close.shift()).abs()
    tr  = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

    atr = tr.ewm(span=n, adjust=False).mean()
    plus_di  = (pd.Series(plus_dm, index=d.index).ewm(span=n, adjust=False).mean()  / atr) * 100
    minus_di = (pd.Series(minus_dm, index=d.index).ewm(span=n, adjust=False).mean() / atr) * 100
    dx = ( (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0, np.nan) ) * 100
    adx = dx.ewm(span=n, adjust=False).mean()

    return plus_di.fillna(0), minus_di.fillna(0), adx.fillna(0)

def _ema(series, span):
    return series.ewm(span=span, adjust=False).mean()

def trend_ema_adx(df, ema_period=50, adx_th=20):
    """
    TƒÉng:  close > EMA v√† EMA d·ªëc l√™n, DI+ > DI-, ADX > ng∆∞·ª°ng
    Gi·∫£m:  close < EMA v√† EMA d·ªëc xu·ªëng, DI- > DI+, ADX > ng∆∞·ª°ng
    Sideway: c√≤n l·∫°i / ADX y·∫øu
    """
    d = _ensure_ohlc(df).copy()
    ema = _ema(d["close"], ema_period)
    plus_di, minus_di, adx = _dmi_adx(d, n=14)

    close_now = float(d["close"].iloc[-1])
    ema_now   = float(ema.iloc[-1])
    ema_prev  = float(ema.iloc[-2]) if len(ema) > 1 else ema_now
    adx_now   = float(adx.iloc[-1])
    pdi_now   = float(plus_di.iloc[-1])
    mdi_now   = float(minus_di.iloc[-1])

    ema_up   = ema_now > ema_prev
    ema_down = ema_now < ema_prev

    if adx_now > adx_th and close_now > ema_now and ema_up and pdi_now > mdi_now:
        return "TƒÉng"
    if adx_now > adx_th and close_now < ema_now and ema_down and mdi_now > pdi_now:
        return "Gi·∫£m"
    return "Sideway"

def calculate_adx(df, period=14):
    high = pd.to_numeric(df["high"], errors="coerce")
    low = pd.to_numeric(df["low"], errors="coerce")
    close = pd.to_numeric(df["close"], errors="coerce")

    plus_dm = high.diff()
    minus_dm = low.diff()
    plus_dm[plus_dm < 0] = 0
    minus_dm[minus_dm > 0] = 0
    minus_dm = abs(minus_dm)

    tr1 = high - low
    tr2 = abs(high - close.shift())
    tr3 = abs(low - close.shift())
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

    atr = tr.rolling(window=period).mean()
    plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr)
    minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr)
    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100
    adx = dx.rolling(window=period).mean()

    df["adx"] = adx
    return df
    
def calculate_indicators(df):
    df["close"] = pd.to_numeric(df["close"], errors="coerce")
    df["ema20"] = df["close"].ewm(span=20).mean()
    df["ema50"] = df["close"].ewm(span=50).mean()
    df["ema100"] = df["close"].ewm(span=100).mean()

    # RSI
    delta = df["close"].diff()
    gain = np.where(delta > 0, delta, 0)
    loss = np.where(delta < 0, -delta, 0)
    avg_gain = pd.Series(gain).rolling(window=14).mean()
    avg_loss = pd.Series(loss).rolling(window=14).mean()
    rs = avg_gain / avg_loss
    df["rsi"] = 100 - (100 / (1 + rs))

    # MACD
    exp1 = df["close"].ewm(span=12).mean()
    exp2 = df["close"].ewm(span=26).mean()
    df["macd"] = exp1 - exp2
    df["macd_signal"] = df["macd"].ewm(span=9).mean()

    df = calculate_adx(df)
    return df
    
def clean_missing_data(df, required_cols=["close", "high", "low", "volume"], max_missing=2):
    missing = df[required_cols].isnull().sum().sum()
    if missing > max_missing:
        return None
    return df.dropna(subset=required_cols)

# ==== EMA200 regime filter (1H/4H) ====
def _get_ec():
    return _ensure_cols if '_ensure_cols' in globals() else ensure_cols
    
def _ema200_up(df, span=200, slope_look=5):
    d = _get_ec()(df.copy()).dropna()
    if "ema200" not in d.columns:
        d["ema200"] = d["close"].ewm(span=span, adjust=False).mean()
    e_now  = float(d["ema200"].iloc[-1])
    e_prev = float(d["ema200"].iloc[-slope_look])
    px_now = float(d["close"].iloc[-1])
    return (px_now > e_now) and (e_now >= e_prev)
    
def _ema200_down(df, span=200, slope_look=5):
    d = _get_ec()(df.copy()).dropna()
    if "ema200" not in d.columns:
        d["ema200"] = d["close"].ewm(span=span, adjust=False).mean()
    e_now  = float(d["ema200"].iloc[-1])
    e_prev = float(d["ema200"].iloc[-slope_look])
    px_now = float(d["close"].iloc[-1])
    return (px_now < e_now) and (e_now <= e_prev)

def _clip01(x): return max(0.0, min(1.0, x))

def score_signal(rr, adx, clv, dist_ema, volp, atr_pct):
    # Chu·∫©n h√≥a th√¥, b·∫°n c√≥ th·ªÉ tinh ch·ªânh:
    s_rr   = _clip01((rr-1.0)/1.5)          # RR 1‚Üí2.5
    s_adx  = _clip01((adx-15)/20)           # ADX 15‚Üí35
    s_clv  = clv if 0<=clv<=1 else 0.5      # ƒë√£ t√≠nh CLV 0..1
    s_dist = _clip01(1 - min(dist_ema / (2*atr_pct + 1e-9), 1))  # c√†ng g·∫ßn EMA/VWAP c√†ng t·ªët
    s_vol  = _clip01((volp-50)/40)          # percentile 50‚Üí90
    return 0.30*s_rr + 0.25*s_adx + 0.20*s_clv + 0.15*s_dist + 0.10*s_vol

# ==== DEBUG BACKTEST ====

# DETECT_SIGNAL
def detect_signal(df_15m: pd.DataFrame,
                  df_1h: pd.DataFrame,
                  symbol: str,
                  cfg: dict = None,
                  silent: bool = True,
                  context: str = "LIVE",
                  return_reason: bool = False):
    fail = []
    sig_score = 0.0
    """
    Return:
      m·∫∑c ƒë·ªãnh: (side, entry, sl, tp, ok)
      n·∫øu return_reason=True: (side, entry, sl, tp, ok, reason_str)
    """
    cfg = cfg or STRICT_CFG
    tg_candidates = []
    # ---- tham s·ªë t·ª´ preset (c√≥ default ƒë·ªÉ kh√¥ng v·ª°) ----
    vol_p        = cfg.get("VOLUME_PERCENTILE", 70)
    adx_min      = cfg.get("ADX_MIN_15M", 20)
    bbw_min      = cfg.get("BBW_MIN", 0.010)
    rr_min       = cfg.get("RR_MIN", 1.5)
    news_win     = cfg.get("NEWS_BLACKOUT_MIN", 60)
    atr_need     = cfg.get("ATR_CLEARANCE_MIN", 0.8)
    use_vwap     = cfg.get("USE_VWAP", True)
    allow_adx_ex = cfg.get("RELAX_EXCEPT", False)

    # n·ªõi/ch·∫∑t theo preset (n·∫øu ƒë√£ th√™m)
    rsi_long_min   = cfg.get("RSI_LONG_MIN", 55)
    rsi_short_max  = cfg.get("RSI_SHORT_MAX", 45)
    rsi1h_long_min = cfg.get("RSI_1H_LONG_MIN", 50)
    rsi1h_short_max= cfg.get("RSI_1H_SHORT_MAX", 50)
    macd_long_min  = cfg.get("MACD_DIFF_LONG_MIN", 0.05)
    macd_short_min = cfg.get("MACD_DIFF_SHORT_MIN", 0.001)
    allow_1h_neu   = cfg.get("ALLOW_1H_NEUTRAL", False)
    body_atr_k     = cfg.get("BREAKOUT_BODY_ATR", 0.6)
    sr_near_pct    = cfg.get("SR_NEAR_PCT", 0.04)  # 4%

    fail = []  # gom l√Ω do r·ªõt

    def _ret(side, entry, sl, tp, ok):
        if return_reason:
            reason = ", ".join(fail) if fail else "PASS"
            # Add EARLY tag for RELAX mode using current bar so downstream can show badge
            try:
                if cfg.get("TAG", "RELAX") == "RELAX" and cfg.get("EARLY_ALERT", False) and cfg.get("EARLY_USE_CURRENT_BAR", False):
                    reason = "[EARLY] " + str(reason)
            except Exception:
                pass
            return side, entry, sl, tp, ok, reason, sig_score
        else:
            return side, entry, sl, tp, ok

    # ---------- d·ªØ li·ªáu & ch·ªâ b√°o c∆° b·∫£n ----------
    if df_15m is None or len(df_15m) < 60:
        fail.append("DATA: thi·∫øu 15m")
        return _ret(None, None, None, None, False)
    df = df_15m.copy()

    # ƒë·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt (kh√¥ng ph√° code c≈©)
    def _ensure_cols(dfx):
        if "ema20" not in dfx.columns: dfx["ema20"] = dfx["close"].ewm(span=20).mean()
        if "ema50" not in dfx.columns: dfx["ema50"] = dfx["close"].ewm(span=50).mean()
        if "rsi" not in dfx.columns:
            delta = dfx["close"].diff()
            gain = delta.clip(lower=0).rolling(14).mean()
            loss = (-delta.clip(upper=0)).rolling(14).mean().replace(0, np.nan)
            rs = gain / loss
            dfx["rsi"] = 100 - (100/(1+rs))
        if "macd" not in dfx.columns or "macd_signal" not in dfx.columns:
            ema12 = dfx["close"].ewm(span=12).mean()
            ema26 = dfx["close"].ewm(span=26).mean()
            dfx["macd"] = ema12 - ema26
            dfx["macd_signal"] = dfx["macd"].ewm(span=9).mean()
        if "bb_width" not in dfx.columns:
            ma20 = dfx["close"].rolling(20).mean()
            std20= dfx["close"].rolling(20).std()
            dfx["bb_upper"] = ma20 + 2*std20
            dfx["bb_lower"] = ma20 - 2*std20
            dfx["bb_width"] = (dfx["bb_upper"] - dfx["bb_lower"]) / dfx["close"]
        if "adx" not in dfx.columns:
            dfx["adx"] = 25.0  # fallback nh·∫π n·∫øu thi·∫øu
        return dfx

    df = _ensure_cols(df).dropna()
    early   = bool(cfg.get("EARLY_ALERT", False))
    use_cur = bool(cfg.get("EARLY_USE_CURRENT_BAR", False))
    # --- EARLY: l·∫•y gi√° tr·ªã n·∫øn n√†o & n·ªõi ti√™u ch√≠ ---
    # v·ªã tr√≠ n·∫øn d√πng ƒë·ªÉ l·ªçc ( -1: n·∫øn ƒëang ch·∫°y, -2: n·∫øn ƒë√£ ƒë√≥ng )
    idx_use = -1 if (early and use_cur) else -2
    dfx = df_1h.copy()
    dfx = _ensure_cols(dfx).dropna()
    side = None
    entry = sl = tp = None
    oke = False
    reason = ""
    sig_score = 0.0
    # l·∫•y gi√° tr·ªã ch·ªâ b√°o ·ªü ƒë√∫ng n·∫øn d√πng
    rsi6  = float(dfx["rsi6"].iloc[idx_use])   if "rsi6"  in dfx.columns  else None
    rsi12 = float(dfx["rsi12"].iloc[idx_use])  if "rsi12" in dfx.columns  else None
    rsi24 = float(dfx["rsi24"].iloc[idx_use])  if "rsi24" in dfx.columns  else None
    macd  = float(dfx["macd"].iloc[idx_use])   if "macd"  in dfx.columns  else None
    clv   = float(dfx["clv"].iloc[idx_use])    if "clv"   in dfx.columns  else None
    adx   = float(dfx["adx"].iloc[idx_use])    if "adx"   in dfx.columns  else 25.0
    
    # ng∆∞·ª°ng g·ªëc (ƒë√£ c√≥ trong cfg c·ªßa b·∫°n)
    RSI_LONG_MIN   = cfg.get("RSI_1H_LONG_MIN", 50)
    RSI_SHORT_MAX  = cfg.get("RSI_1H_SHORT_MAX", 50)
    MACD_LONG_MIN  = cfg.get("MACD_DIFF_LONG_MIN", 0.05)
    MACD_SHORT_MIN = cfg.get("MACD_DIFF_SHORT_MIN", 0.01)
    CLV_MIN        = cfg.get("CLV_MIN", 0.60)
    ADX_MIN        = cfg.get("ADX_MIN", 18)
    
    # n·ªõi ti√™u ch√≠ khi EARLY + d√πng n·∫øn hi·ªán t·∫°i
    if early and use_cur:
        # gi·∫£m y√™u c·∫ßu RSI/MACD/CLV ~10% v√† h·∫° ADX 2 ƒëi·ªÉm
        RSI_LONG_MIN   = max(0, RSI_LONG_MIN - 3)           # vd 50 -> 47
        RSI_SHORT_MAX  = min(100, RSI_SHORT_MAX + 3)        # vd 50 -> 53
        MACD_LONG_MIN  = MACD_LONG_MIN * 0.9                # vd 0.05 -> 0.045
        MACD_SHORT_MIN = MACD_SHORT_MIN * 0.9               # vd 0.01 -> 0.009
        CLV_MIN        = CLV_MIN * 0.9                      # vd 0.60 -> 0.54
        ADX_MIN        = max(0, ADX_MIN - 2)
    
    # quy·∫øt ƒë·ªãnh chi·ªÅu theo side hi·ªán t·∫°i
    def pass_filters(side: str) -> (bool, str):
        reasons = []
        if side == "LONG":
            if rsi12 is not None and rsi12 < RSI_LONG_MIN:
                reasons.append(f"RSI12<{RSI_LONG_MIN}")
            if macd is not None and macd < MACD_LONG_MIN:
                reasons.append(f"MACD<{MACD_LONG_MIN:.3f}")
            if clv is not None and clv < CLV_MIN:
                reasons.append(f"CLV<{CLV_MIN:.2f}")
            if adx is not None and adx < ADX_MIN:
                reasons.append(f"ADX<{ADX_MIN}")
        else:  # SHORT
            if rsi12 is not None and rsi12 > RSI_SHORT_MAX:
                reasons.append(f"RSI12>{RSI_SHORT_MAX}")
            if macd is not None and macd > -MACD_SHORT_MIN:  # macd √¢m ƒë·ªß m·∫°nh
                reasons.append(f"MACD>-{MACD_SHORT_MIN:.3f}")
            if clv is not None and clv > (1 - CLV_MIN):
                reasons.append(f"CLV>{1-CLV_MIN:.2f}")
            if adx is not None and adx < ADX_MIN:
                reasons.append(f"ADX<{ADX_MIN}")
    
        return (len(reasons) == 0, "PASS" if not reasons else ", ".join(reasons))
    
    # v√≠ d·ª• d√πng:
    # must have side before filtering
    if not side:
        return side, entry, sl, tp, False, "[SKIP] side not decided", sig_score

    ok, reason = pass_filters(side)
    # n·∫øu b·∫°n c·∫ßn g·∫Øn tag EARLY ƒë·ªÉ hi·ªÉn th·ªã:
    if early and use_cur:
        reason = "[EARLY] " + reason
    # n·∫øn d√πng ƒë·ªÉ ra quy·∫øt ƒë·ªãnh
    bar_idx = -1 if (early and use_cur) else -2
    cur  = df.iloc[bar_idx]
    prev = df.iloc[bar_idx-1]
    
    # ch·ªëng b√°o qu√° s·ªõm khi n·∫øn v·ª´a m·ªü (v√≠ d·ª• TF 1h: ƒë√≤i √≠t nh·∫•t 20')
    min_age_min = int(cfg.get("EARLY_MIN_AGE_MIN", 20))
    if early and use_cur:
        # df n√™n c√≥ c·ªôt 'ts' (ms) ho·∫∑c DatetimeIndex; ƒë·ªïi ra ph√∫t ƒë√£ tr√¥i qua trong n·∫øn
        last_ts = int(cur.get("timestamp", getattr(cur, "ts", 0)))  # ms
        bar_sec = 60 * 60  # TF 1h (n·∫øu TF kh√°c, ƒë·ªïi theo)
        now_sec = int(time.time())
        bar_start = (last_ts // 1000 // bar_sec) * bar_sec
        age_min = (now_sec - bar_start) // 60
        if age_min < min_age_min:
            return _ret(side=None, entry=None, sl=None, tp=None, ok=False)  # ƒë·ª£i th√™m
    last_idx = -1 if (early and use_cur) else -2   # -1: n·∫øn ƒëang ch·∫°y, -2: n·∫øn ƒë√£ ƒë√≥ng
    latest = df.iloc[last_idx]
    price  = float(latest["close"])
    # ---------- volume percentile ----------
    vols = df["volume"].iloc[-20:]
    if len(vols) < 10:
        fail.append("DATA: thi·∫øu volume 15m")
        return _ret(None, None, None, None, False)
    
    v_now = float(vols.iloc[-1])
    v_thr = float(np.percentile(vols.iloc[:-1], vol_p))
    
    # LOG chi ti·∫øt ·ªü m·ª©c INFO
    logging.info(f"[VOL] {symbol}: v_now={v_now:.0f}, v_thr(P{vol_p})={v_thr:.0f}")
    
    if not (v_now >= v_thr):
        # ƒë∆∞a s·ªë v√†o reason ƒë·ªÉ hi·ªán ngay ·ªü log INFO c·ªßa b·∫°n
        fail.append(f"VOLUME < P{vol_p} (v_now={v_now:.0f} < {v_thr:.0f})")

    # ---------- choppy filter: ADX + BBWidth ----------
    adx = float(df["adx"].iloc[-1]); bbw = float(df["bb_width"].iloc[-1])
    if adx < adx_min and not allow_adx_ex:
        fail.append(f"ADX {adx:.1f}<{adx_min}")
    if bbw < bbw_min:
        fail.append(f"BBW {bbw:.4f}<{bbw_min}")

    # ngo·∫°i l·ªá ADX (RELAX): b·∫Øt bu·ªôc body >= k*ATR
    if adx < adx_min and allow_adx_ex:
        last = df.iloc[last_idx]
        body = abs(last["close"] - last["open"])
        atr  = float(_atr(df).iloc[-1])
        if not (atr > 0 and body >= body_atr_k * atr):
            fail.append("ADX-except: body<k*ATR")

    # ---------- x√°c nh·∫≠n ƒëa khung ----------
    ema_up_15 = latest["ema20"] > latest["ema50"]
    ema_dn_15 = latest["ema20"] < latest["ema50"]
    rsi_15    = float(latest["rsi"])
    macd_diff = abs(float(latest["macd"] - latest["macd_signal"])) / max(price, 1e-9)

    if df_1h is not None and len(df_1h) > 60:
        d1 = _ensure_cols(df_1h.copy()).dropna()
        l1 = d1.iloc[-1]
        ema_up_1h = bool(l1["ema20"] > l1["ema50"])
        rsi_1h    = float(l1["rsi"])
    else:
        ema_up_1h = True; rsi_1h = 50.0

    cond_1h_long_ok  = (ema_up_1h and rsi_1h > rsi1h_long_min) or (allow_1h_neu and ema_up_1h)
    cond_1h_short_ok = ((not ema_up_1h) and rsi_1h < rsi1h_short_max) or (allow_1h_neu and (not ema_up_1h))
    
    # X√°c ƒë·ªãnh mode & c·ªù multi‚Äëtimeframe t·ª´ ch√≠nh cfg
    mode = cfg.get("TAG", "RELAX")                # "STRICT" ho·∫∑c "RELAX"
    require_multi = cfg.get("REQ_EMA200_MULTI", False)
    if require_multi:
        ok_1h = ok_4h = True
        try:
            ok_1h = _ema200_up(df_1h) if side == "LONG" else _ema200_down(df_1h)
        except Exception:
            pass
        try:
            ok_4h = _ema200_up(df_4h) if side == "LONG" else _ema200_down(df_4h)
        except Exception:
            pass
    
        if mode == "STRICT":
            if not (ok_1h and ok_4h):
                fail.append("REGIME: EMA200 1H/4H kh√¥ng ƒë·ªìng h∆∞·ªõng")
                return _ret(None, None, None, None, False)
        else:  # RELAX
            if not (ok_1h or ok_4h):
                fail.append("REGIME: EMA200 thi·∫øu x√°c nh·∫≠n (RELAX)")
                return _ret(None, None, None, None, False)
            
    # ===== X√ÅC NH·∫¨N H∆Ø·ªöNG & ƒê·ªíNG PHA (STRICT=3/3, RELAX>=2/3) =====
    side = None
    
    # vote theo 3 nh√≥m: EMA(+1), RSI(+1), MACD(+1)
    long_vote  = 0
    short_vote = 0
    
    # 1) EMA (15m + x√°c nh·∫≠n 1h)
    if ema_up_15 and cond_1h_long_ok:
        long_vote += 1
    elif ema_dn_15 and cond_1h_short_ok:
        short_vote += 1
    
    # 2) RSI
    if rsi_15 > rsi_long_min:
        long_vote += 1
    elif rsi_15 < rsi_short_max:
        short_vote += 1
    
    # 3) MACD: d√πng h∆∞·ªõng th√¥ (macd - signal) + ng∆∞·ª°ng ƒë·ªô l·ªõn macd_diff
    macd_raw = float(latest["macd"]) - float(latest["macd_signal"])
    if macd_raw > 0 and macd_diff > macd_long_min:
        long_vote += 1
    elif macd_raw < 0 and macd_diff > macd_short_min:
        short_vote += 1
    
    # y√™u c·∫ßu ƒë·ªìng pha: RELAX=2/3, STRICT=3/3
    need_align = 2 if cfg.get("TAG", "STRICT") == "RELAX" else 3
    
    # x√©t ADX c√πng l√∫c (gi·ªØ nguy√™n ng∆∞·ª°ng b·∫°n ƒë√£ ƒë·∫∑t)
    if long_vote >= need_align and adx >= adx_min:
        side = "LONG"
    elif short_vote >= need_align and adx >= adx_min:
        side = "SHORT"
    else:
        # b√°o l√Ω do r·ªõt chi ti·∫øt
        best = max(long_vote, short_vote)
        fail.append(f"ALIGN {best}/3 (y/c {need_align}/3)")
        if adx < adx_min:
            fail.append(f"ADX {adx:.1f} < {adx_min}")
    
    # n·∫øu ƒë√£ c√≥ l·ªói ·ªü tr√™n, tr·∫£ s·ªõm
    if fail:
        return _ret(None, None, None, None, False)


    # ---------- √©p v·ªã tr√≠ near S/R theo h∆∞·ªõng ----------
    try:
        low_sr, high_sr = find_support_resistance(df, lookback=40)
    except Exception:
        low_sr = float(df["low"].iloc[-40:-1].min())
        high_sr= float(df["high"].iloc[-40:-1].max())
    px = price
    near_sup = abs(px - low_sr)/max(low_sr,1e-9) <= sr_near_pct
    near_res = abs(px - high_sr)/max(high_sr,1e-9) <= sr_near_pct
    if side == "LONG" and not near_sup:   fail.append("SR: kh√¥ng near support")
    if side == "SHORT" and not near_res:  fail.append("SR: kh√¥ng near resistance")
    if fail: return _ret(None, None, None, None, False)

    # ===== EXTRA PRO FILTERS (veto n·∫øu kh√¥ng ƒë·∫°t) =====
    try:
        # 1) Divergence veto (d√πng RSI n·∫øu c√≥, fallback MACD histogram)
        osc = df["rsi"] if "rsi" in df.columns else (df["macd"] - df["macd_signal"] if "macd" in df.columns and "macd_signal" in df.columns else None)
        if osc is not None:
            if side == "LONG"  and is_bear_div(df["close"], osc, lb=30, win=3):
                fail.append("DIVERGENCE (bear)");  return _ret(None, None, None, None, False)
            if side == "SHORT" and is_bull_div(df["close"], osc, lb=30, win=3):
                fail.append("DIVERGENCE (bull)");  return _ret(None, None, None, None, False)
    
        # 2) Wick quality (tr√°nh r√¢u ng∆∞·ª£c qu√° l·ªõn)
        last = df.iloc[last_idx]
        rng   = max(float(last["high"]) - float(last["low"]), 1e-9)
        body  = abs(float(last["close"]) - float(last["open"]))
        upper = float(last["high"]) - max(float(last["close"]), float(last["open"]))
        lower = min(float(last["close"]), float(last["open"])) - float(last["low"])
        if side == "LONG"  and upper >= WICK_RATIO_LIMIT * rng:
            fail.append("UPPER-WICK");  return _ret(None, None, None, None, False)
        if side == "SHORT" and lower >= WICK_RATIO_LIMIT * rng:
            fail.append("LOWER-WICK");  return _ret(None, None, None, None, False)
    
        # 3) CLV (Close near extreme c·ªßa n·∫øn t√≠n hi·ªáu)
        clv = (float(last["close"]) - float(last["low"])) / rng  # 0..1
        if side == "LONG"  and clv < 0.60:
            fail.append("CLV<0.60");   return _ret(None, None, None, None, False)
        if side == "SHORT" and clv > 0.40:
            fail.append("CLV>0.40");   return _ret(None, None, None, None, False)
    
        # 4) ATR expansion (ATR hi·ªán t·∫°i > median ATR 20 n·∫øn tr∆∞·ªõc * 1.2)
        atr_s   = _atr(df, n=14)
        atr_now = float(atr_s.iloc[-1]) if atr_s is not None and len(atr_s) else None
        px      = float(last["close"])
        
        k_atr = cfg.get("SR_NEAR_K_ATR", 0.6)   # c≈© l√† 0.6
        pct   = cfg.get("SR_NEAR_PCT", 0.008)   # c≈© ~ 0.8%
        
        tol_abs = 0.0
        if atr_now:
            tol_abs = max(tol_abs, k_atr * atr_now)
        tol_abs = max(tol_abs, pct * px)
        
        if side == "LONG":
            # c·∫ßn g·∫ßn KH√ÅNG C·ª∞ (high_sr)
            if "high_sr" in locals() and high_sr is not None:
                if abs(px - float(high_sr)) > tol_abs:
                    fail.append("SR: kh√¥ng near resistance")
                    return _ret(None,None,None,None,False)
        elif side == "SHORT":
            # c·∫ßn g·∫ßn H·ªñ TR·ª¢ (low_sr)
            if "low_sr" in locals() and low_sr is not None:
                if abs(px - float(low_sr)) > tol_abs:
                    fail.append("SR: kh√¥ng near support")
                    return _ret(None,None,None,None,False)
    except Exception as _e:
        # An to√†n: n·∫øu filter ph·ª• l·ªói th√¨ b·ªè qua (kh√¥ng l√†m h·ªèng lu·ªìng ch√≠nh)
        logging.debug(f"[EXTRA-FILTER] skip due to error: {_e}")
    
    # ---------- Divergence veto (RSI/MACD) ----------
    osc = df["rsi"] if "rsi" in df.columns else (df["macd"]-df["macd_signal"] if {"macd","macd_signal"}<=set(df.columns) else None)
    if osc is not None:
        if side=="LONG"  and is_bear_div(df["close"], osc, lb=30, win=3):
            fail.append("DIVERGENCE"); return _ret(None,None,None,None,False)
        if side=="SHORT" and is_bull_div(df["close"], osc, lb=30, win=3):
            fail.append("DIVERGENCE"); return _ret(None,None,None,None,False)     
    
    # ---------- Wick ration (r√¢u n·∫øn x·∫•u) ----------
    last=df.iloc[-1]; rng=max(float(last.high)-float(last.low),1e-9)
    upper=float(last.high)-max(float(last.close),float(last.open))
    lower=min(float(last.close),float(last.open))-float(last.low)
    if side=="LONG"  and upper>=0.5*rng:  fail.append("UPPER-WICK");  return _ret(None,None,None,None,False)
    if side=="SHORT" and lower>=0.5*rng:  fail.append("LOWER-WICK");  return _ret(None,None,None,None,False)

    # ---------- CLV (Close g·∫ßn c·ª±c tr·ªã n·∫øn) ----------
    clv=(float(last.close)-float(last.low))/rng
    if side=="LONG"  and clv<0.60: fail.append("CLV<0.60");  return _ret(None,None,None,None,False)
    if side=="SHORT" and clv>0.40: fail.append("CLV>0.40");  return _ret(None,None,None,None,False)

    # ---------- Breakout ph·∫£i c√≥ retest nh·∫π (>= 1 n·∫øn tr∆∞·ªõc ƒë√≥) ----------
    require_retest = cfg.get("REQUIRE_RETEST", True)
    brk_level = high_sr if side == "LONG" else low_sr
    pre = df.tail(4)[:-1]
    if np.isfinite(brk_level) and require_retest:
        if side == "LONG":
            ok = any(float(r.low)  <= brk_level <= float(r.close) for _, r in pre.iterrows())
        else:
            ok = any(float(r.close) <= brk_level <= float(r.high) for _, r in pre.iterrows())
        if not ok:
            fail.append("NO-RETEST")
            return _ret(None, None, None, None, False)
            
    # ---------- Bar exhaustion (n·∫øn qu√° d√†i -> d·ªÖ h·ª•t h∆°i) ----------
    if float(last.high)-float(last.low) > 1.8*float(_atr(df,14).iloc[-1]):
        fail.append("EXHAUSTION-BAR"); return _ret(None,None,None,None,False)

    # ---------- Bar- since-break (tr√°nh v√†o tr·ªÖ, ch·ªâ ghi nh·∫≠n c√∫ break ƒë·∫ßu) ----------
    pre=df.tail(10)[:-1]
    if side=="LONG"  and any(float(r.close)>brk_level for _,r in pre.iterrows()):
        fail.append("LATE-BREAK"); return _ret(None,None,None,None,False)
    if side=="SHORT" and any(float(r.close)<brk_level for _,r in pre.iterrows()):
        fail.append("LATE-BREAK"); return _ret(None,None,None,None,False)
        
    # ---------- Away from mean (kh√¥ng ƒëu qu√° xa EMA/VWAP) ----------
    ema20=df["ema20"].iloc[-1] if "ema20" in df.columns else None
    vwap =df["vwap"].iloc[-1]  if "vwap"  in df.columns else None
    atr14=float(_atr(df,14).iloc[-1])
    if side=="LONG":
        if ema20 and (float(last.close)-float(ema20))>1.0*atr14: fail.append("AWAY-EMA20"); return _ret(None,None,None,None,False)
        if vwap  and (float(last.close)-float(vwap)) >1.2*atr14: fail.append("AWAY-VWAP");  return _ret(None,None,None,None,False)
    else:
        if ema20 and (float(ema20)-float(last.close))>1.0*atr14: fail.append("AWAY-EMA20"); return _ret(None,None,None,None,False)
        if vwap  and (float(vwap) -float(last.close))>1.2*atr14: fail.append("AWAY-VWAP");  return _ret(None,None,None,None,False)
                      
    # ---------- Entry/SL/TP/RR ----------
    if side == "LONG":
        sl = float(df["low"].iloc[-10:-1].min())
        tp = float(df["high"].iloc[-10:-1].max())
    else:
        sl = float(df["high"].iloc[-10:-1].max())
        tp = float(df["low"].iloc[-10:-1].min())
    
    entry = px
    # --- Check SL/TP/RR ƒë·ªông theo ATR ---
    atr_s  = _atr(df, n=14)
    atr_now = float(atr_s.iloc[-1]) if atr_s is not None and len(atr_s) else None
    atr_pct = (atr_now / max(entry, 1e-9)) if atr_now else 0.0
    
    sl_min_pct_base = SL_MIN_PCT_BASE
    tp_min_pct_base = TP_MIN_STRICT_BASE if mode == "STRICT" else TP_MIN_RELAX_BASE
    
    sl_min_pct_dyn  = max(sl_min_pct_base, K_ATR_SL * atr_pct)
    tp_min_pct_dyn  = max(tp_min_pct_base, K_ATR_TP * atr_pct)
    
    sl_pct = abs(entry - sl) / max(entry, 1e-9)
    if sl_pct < sl_min_pct_dyn:
        fail.append(f"SL<{sl_min_pct_dyn*100:.2f}%")
        return _ret(None, None, None, None, False)
    
    tp_pct = abs(tp - entry) / max(entry, 1e-9)
    if tp_pct < tp_min_pct_dyn:
        fail.append(f"TP<{tp_min_pct_dyn*100:.2f}%")
        return _ret(None, None, None, None, False)
    
    rr_min = (STRICT_CFG if mode == "STRICT" else RELAX_CFG)["RR_MIN"]
    risk = max(abs(entry - sl), 1e-9)
    rr = abs(tp - entry) / risk
    if rr < rr_min:
        fail.append(f"RR {rr:.2f}<{rr_min}")
        return _ret(None, None, None, None, False)
                      
    # ---------- news blackout ----------
    try:
        if in_news_blackout(news_win):
            fail.append("NEWS blackout")
    except Exception:
        pass
    if fail: return _ret(None, None, None, None, False)

    # ---------- anchored VWAP blocker ----------
    if use_vwap and len(df) > 55:
        try:
            aidx = pick_anchor_index(df, side)
            if not isinstance(aidx, int):
                try:
                    aidx = df.index.get_loc(aidx)
                except Exception:
                    aidx = max(0, len(df)-50)
            vwap = anchored_vwap(df, aidx)
            dist = abs(entry - vwap)/max(vwap,1e-9)
            if dist <= 0.001 and ((side=="LONG" and entry < vwap) or (side=="SHORT" and entry > vwap)):
                fail.append("VWAP ch·∫∑n")
        except Exception:
            pass
    if fail: return _ret(None, None, None, None, False)

    # ---------- ATR clearance (c·∫£n g·∫ßn) ----------
    try:
        clr_ratio, clr_ok = atr_clearance(df, side, atr_need)
        if not clr_ok:
            fail.append(f"ATR clearance {clr_ratio:.2f}<{atr_need}")
    except Exception:
        pass
    if fail: return _ret(None, None, None, None, False)

    # ---------- ƒê·ªìng pha BTC ----------
    try:
        btc_1h = fetch_ohlcv_okx("BTC-USDT-SWAP", "1h")
        btc_up_1h = True
        if isinstance(btc_1h, pd.DataFrame) and len(btc_1h) > 60:
            b1 = calculate_indicators(btc_1h.copy()).dropna().iloc[-1]
            btc_up_1h = bool(b1["ema20"] > b1["ema50"])
        if side == "LONG" and not btc_up_1h:  fail.append("BTC ng∆∞·ª£c h∆∞·ªõng 1h")
        if side == "SHORT" and btc_up_1h:     fail.append("BTC ng∆∞·ª£c h∆∞·ªõng 1h")
        # bi·∫øn ƒë·ªông 15m ng·∫Øn h·∫°n
        btc_15 = fetch_ohlcv_okx("BTC-USDT-SWAP", "15m")
        if isinstance(btc_15, pd.DataFrame) and len(btc_15) > 5:
            c0 = float(btc_15["close"].iloc[-1]); c3 = float(btc_15["close"].iloc[-4])
            chg = (c0 - c3)/max(c3,1e-9)
            if side == "LONG" and chg < -0.01: fail.append("BTC -1%/45m")
            if side == "SHORT" and chg >  0.01: fail.append("BTC +1%/45m")
    except Exception:
        pass
    if fail: return _ret(None, None, None, None, False)

    # ---------- PASS ----------
    if not silent:
        logging.info(f"‚úÖ {symbol} V∆Ø·ª¢T QUA H·∫æT B·ªò L·ªåC ({side})")
    # --- ATR% tr√™n gi√° hi·ªán t·∫°i (d√πng ƒë·ªÉ chu·∫©n ho√° kho·∫£ng c√°ch EMA/VWAP) ---
    price  = float(df_15m["close"].iloc[-1])
    atr14  = float(_atr(df_15m, 14).iloc[-1])          # b·∫°n ƒë√£ c√≥ _atr(df, n) ·ªü ch·ªó kh√°c
    atr_pct = atr14 / max(price, 1e-9)                 # v√≠ d·ª•: 0.012 = 1.2%
    # an to√†n: n·∫øu NaN/inf th√¨ g√°n m·∫∑c ƒë·ªãnh
    if not (0 < atr_pct < 1e3):
        atr_pct = 0.01    
    # ---------- T√≠nh score t√≠n hi·ªáu ----------
    adx_val  = float(df["adx"].iloc[-1]) if "adx" in df.columns else 20.0
    clv      = (float(last["close"])-float(last["low"])) / max(float(last["high"])-float(last["low"]),1e-9)
    dist_ema = abs(float(last["close"]) - float(last.get("ema20", float(last["close"]))))
    volp     = vol_p if 'vol_p' in locals() else 60
    
    sig_score = score_signal(rr, adx_val, clv, dist_ema, volp, atr_pct)
    
    # L∆∞u th√™m score v√†o tg_candidates               
    return _ret(side, float(entry), float(sl), float(tp), True)

def analyze_trend_multi(symbol):
    tf_map = {
        'short': ['1H', '4H', '1D', '1W'],
        'mid':   ['1D', '1W', '1W', '1M']
    }

    def get_score(tf):
        try:
            df = fetch_ohlcv(symbol, tf.lower(), 50)
            df = calculate_indicators(df)
            rsi = df['rsi'].iloc[-1]
            ema20 = df['ema20'].iloc[-1]
            ema50 = df['ema50'].iloc[-1]
            return 2 if (rsi > 60 and ema20 > ema50) else 1 if (rsi > 50 and ema20 > ema50) else 0
        except:
            return 0

    short_score = sum([get_score(tf) for tf in tf_map['short']])
    mid_score = sum([get_score(tf) for tf in tf_map['mid']])

    def to_text(score):
        return "TƒÉng (‚òÖ‚òÖ‚òÖ)" if score >= 6 else "Kh√¥ng r√µ (‚òÖ)" if score >= 2 else "Gi·∫£m (‚úñ)"

    return to_text(short_score), to_text(mid_score)
 

def calculate_signal_rating(signal, short_trend, mid_trend, volume_ok):
    if signal == "LONG" and short_trend.startswith("TƒÉng") and mid_trend.startswith("TƒÉng") and volume_ok:
        return 5
    elif signal == "SHORT" and short_trend.startswith("Gi·∫£m") and mid_trend.startswith("Gi·∫£m"):
        return 5
    elif short_trend.startswith("TƒÉng") and mid_trend.startswith("TƒÉng"):
        return 4
    elif short_trend.startswith("Gi·∫£m") and mid_trend.startswith("Gi·∫£m"):
        return 4
    elif signal in ["LONG", "SHORT"]:
        return 3
    else:
        return 2

def _to_user_entered(x):
    if x is None:
        return ""
    if isinstance(x, float):
        s = f"{x:.8f}".rstrip("0").rstrip(".")
        return s if s else "0"
    return str(x)


VN_TZ = pytz.timezone("Asia/Ho_Chi_Minh")
def parse_vn_time(s):
    """Tr·∫£ v·ªÅ datetime c√≥ tz; h·ªó tr·ª£ nhi·ªÅu format t·ª´ Google Sheets."""
    if s is None or s == "":
        return None
    # N·∫øu ƒë√£ l√† datetime
    if isinstance(s, dt.datetime):
        return s if s.tzinfo else VN_TZ.localize(s)

    s = str(s).strip().replace("Z", "+00:00")  # ISO 'Z' -> +00:00

    formats = [
        "%d/%m/%Y %H:%M",          # 11/08/2025 16:10
        "%Y-%m-%d %H:%M:%S%z",     # 2025-08-11 16:10:00+07:00  <-- QUAN TR·ªåNG
        "%Y-%m-%dT%H:%M:%S%z",     # 2025-08-11T16:10:00+07:00
        "%Y-%m-%d %H:%M:%S",       # 2025-08-11 16:10:00 (naive)
        "%Y-%m-%dT%H:%M:%S",       # 2025-08-11T16:10:00 (naive)
        "%Y-%m-%d %H:%M",          # 2025-08-11 16:10
        "%Y-%m-%dT%H:%M",          # 2025-08-11T16:10
    ]
    for fmt in formats:
        try:
            d = dt.datetime.strptime(s, fmt)
            return d if d.tzinfo else VN_TZ.localize(d)
        except Exception:
            pass
    return None

def prepend_with_retention(ws, new_rows, keep_days=3):
    """
    Ch√®n new_rows l√™n ƒë·∫ßu Google Sheet ws, gi·ªØ l·∫°i d·ªØ li·ªáu c≈© trong v√≤ng keep_days ng√†y.
    new_rows: list of lists (m·ªói list l√† 1 d√≤ng)
    """
    try:
        # L·∫•y to√†n b·ªô d·ªØ li·ªáu hi·ªán t·∫°i
        existing_data = ws.get_all_values()

        # N·∫øu sheet ƒëang tr·ªëng ‚Üí th√™m header tr∆∞·ªõc
        if not existing_data:
            headers = ["Coin", "T√≠n hi·ªáu", "Entry", "SL", "TP", "Xu h∆∞·ªõng ng·∫Øn", "Xu h∆∞·ªõng trung", "Ng√†y", "Mode"]
            ws.insert_row(headers, 1)
            existing_data = [headers]

        headers = existing_data[0]
        old_rows = existing_data[1:]

        # L·ªçc d·ªØ li·ªáu c≈© theo ng√†y
        today = datetime.now(pytz.timezone("Asia/Ho_Chi_Minh")).date()
        retained_rows = []
        for row in old_rows:
            try:
                date_str = row[7]  # C·ªôt Ng√†y (index 7)
                if date_str.strip():
                    row_date = datetime.strptime(date_str, "%d/%m/%Y %H:%M").date()
                    if (today - row_date).days <= keep_days:
                        retained_rows.append(row)
                    else:
                        pass  # qu√° h·∫°n ‚Üí b·ªè
                else:
                    retained_rows.append(row)  # n·∫øu kh√¥ng c√≥ ng√†y ‚Üí gi·ªØ nguy√™n
            except Exception:
                retained_rows.append(row)  # l·ªói parse ng√†y ‚Üí gi·ªØ nguy√™n

        # ƒê·∫£m b·∫£o m·ªói d√≤ng ƒë·ªÅu c√≥ 9 c·ªôt
        def normalize_row(r):
            r = list(r)
            while len(r) < 9:
                r.append("")
            return r[:9]

        new_rows_norm = [normalize_row(r) for r in new_rows]
        retained_rows_norm = [normalize_row(r) for r in retained_rows]

        # G·ªôp l·∫°i: header + 5 d√≤ng m·ªõi + d·ªØ li·ªáu c≈© (ƒë√£ l·ªçc)
        final_data = [headers] + new_rows_norm + retained_rows_norm

        # X√≥a d·ªØ li·ªáu c≈© r·ªìi ghi l·∫°i
        ws.clear()
        ws.update("A1", final_data)

        logging.info(f"[SHEET] ‚úÖ Prepend {len(new_rows_norm)} d√≤ng m·ªõi, gi·ªØ l·∫°i {len(retained_rows_norm)} d√≤ng c≈© (‚â§ {keep_days} ng√†y)")

    except Exception as e:
        logging.error(f"[SHEET] L·ªói khi prepend_with_retention: {e}")
# === t√≠nh sao ===
def stars(n:int) -> str:
    n = max(0, min(5, int(n)))
    return "‚≠ê" * n
    
# === G·ª¨I TELEGRAM ===
def send_telegram_message(message):
    try:
        token = TELEGRAM_TOKEN
        chat_id = TELEGRAM_CHAT_ID
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": message,
            "parse_mode": "HTML"
        }
        response = requests.post(url, data=payload)
        if response.status_code != 200:
            logging.warning(f"Telegram error: {response.text}")
    except Exception as e:
        logging.error(f"‚ùå L·ªói g·ª≠i Telegram: {e}")
        
def run_bot():
    logging.basicConfig(level=logging.INFO)
    coin_list = get_top_usdt_pairs(limit=COINS_LIMIT)

    # b·ªô nh·ªõ t·∫°m ƒë·ªÉ G·ªòP k·∫øt qu·∫£
    sheet_rows = []          # m·ªói ph·∫ßn t·ª≠ = row prepend_to_sheet([...]) theo format g·ªëc c·ªßa b·∫°n
    tg_candidates = []       # (mode, symbol, side, entry, sl, tp, rating, sig_score)

    # -------- STRICT pass --------
    reset_log_once_for_mode("STRICT", coin_list)
    strict_hits = set()

    for symbol in coin_list:
        ok = False; side = entry = sl = tp = None; rating = 0

        with mute_logs():
            inst_id = symbol.upper().replace("/", "-") + "-SWAP"
            df_15m = fetch_ohlcv_okx(inst_id, "15m")
            df_1h  = fetch_ohlcv_okx(inst_id, "1h")
            if isinstance(df_15m, pd.DataFrame) and isinstance(df_1h, pd.DataFrame):
                df_15m = calculate_indicators(df_15m).dropna()
                df_1h  = calculate_indicators(df_1h ).dropna()
                side, entry, sl, tp, ok, reason, sig_score = detect_signal(
                    df_15m, df_1h, symbol,
                    cfg=STRICT_CFG, silent=True, context="LIVE-STRICT",
                    return_reason=True
                )
          
                if ok:
                    strict_hits.add(symbol)
                
                    # ---- trends (d√πng cho rating) ----
                    try:
                        trend_s = trend_ema_adx(df_15m, ema_period=50, adx_th=20)   # 'TƒÉng' / 'Gi·∫£m' / 'Trung l·∫≠p'
                    except Exception:
                        trend_s = "?"
                
                    try:
                        trend_m = trend_ema_adx(df_1h, ema_period=100, adx_th=20)
                    except Exception:
                        trend_m = "?"
                
                    # ---- volume_ok l·∫•y t·ª´ filter volume ·ªü tr√™n ----
                    volume_ok = True
                    try:
                        volume_ok = (v_now >= v_thr)
                    except NameError:
                        volume_ok = True
                
                    # ---- rating ----
                    try:
                        if 'calculate_signal_rating' in globals():
                            rating = int(calculate_signal_rating(side, trend_s, trend_m, volume_ok))
                        else:
                            rating = 3
                            if side == "LONG" and trend_s.startswith("TƒÉng") and trend_m.startswith("TƒÉng"):
                                rating = 5 if volume_ok else 4
                            elif side == "SHORT" and trend_s.startswith("Gi·∫£m") and trend_m.startswith("Gi·∫£m"):
                                rating = 5 if volume_ok else 4
                            elif (trend_s[:1] == trend_m[:1]) and trend_s[:1] in ("T", "G"):
                                rating = 4
                    except Exception:
                        rating = 3
                    now_vn = dt.datetime.now(pytz.timezone("Asia/Ho_Chi_Minh")).strftime("%d/%m/%Y %H:%M")
                    # gi·ªØ ƒê√öNG format prepend_to_sheet g·ªëc c·ªßa b·∫°n:
                    side_with_stars = f"{side}{'‚≠ê'*max(1, min(rating, 5))}"
                    sheet_rows.append([symbol, side_with_stars, entry, sl, tp, trend_s, trend_m, now_vn, "STRICT"])
                    tg_candidates.append(("STRICT", symbol, side, entry, sl, tp, rating, sig_score))

        # log t√≥m t·∫Øt 1 d√≤ng/coin
        if ok:
            log_once("STRICT", symbol, f"[STRICT] {symbol}: ‚úÖ PASS", "info")
        else:
            log_once("STRICT", symbol, f"[STRICT] {symbol}: ‚ùå r·ªõt filter ‚Äì {reason}", "info")

    # -------- RELAX pass (b·ªè symbol ƒë√£ ra ·ªü STRICT) --------
    relax_list = [s for s in coin_list if s not in strict_hits]
    reset_log_once_for_mode("RELAX", relax_list)

    for symbol in relax_list:
        ok = False; side = entry = sl = tp = None; rating = 0

        with mute_logs():
            inst_id = symbol.upper().replace("/", "-") + "-SWAP"
            df_15m = fetch_ohlcv_okx(inst_id, "15m")
            df_1h  = fetch_ohlcv_okx(inst_id, "1h")
            if isinstance(df_15m, pd.DataFrame) and isinstance(df_1h, pd.DataFrame):
                df_15m = calculate_indicators(df_15m).dropna()
                df_1h  = calculate_indicators(df_1h ).dropna()
                side, entry, sl, tp, ok, reason, sig_score = detect_signal(
                    df_15m, df_1h, symbol,
                    cfg=RELAX_CFG, silent=True, context="LIVE-RELAX",
                    return_reason=True
                )
            
                if ok:                    
                    # ---- trends (ph·ª•c v·ª• rating) ----
                    try:
                        trend_s = trend_ema_adx(df_15m, ema_period=50, adx_th=20)
                    except Exception:
                        trend_s = "?"
                    try:
                        trend_m = trend_ema_adx(df_1h, ema_period=100, adx_th=20)
                    except Exception:
                        trend_m = "?"
                    
                    # ---- rating ----
                    rating = 3
                    try:
                        # volume_ok n·∫øu c√≥ v_now/v_thr; n·∫øu kh√¥ng c√≥ th√¨ coi nh∆∞ True ƒë·ªÉ kh√¥ng crash
                        try:
                            volume_ok = (v_now >= v_thr)
                        except Exception:
                            volume_ok = True
                    
                        if 'calculate_signal_rating' in globals():
                            rating = int(calculate_signal_rating(side, trend_s, trend_m, volume_ok))
                        else:
                            # fallback ƒë∆°n gi·∫£n
                            if side == "LONG"  and trend_s.startswith("T") and trend_m.startswith("T"):
                                rating = 5 if volume_ok else 4
                            elif side == "SHORT" and trend_s.startswith("G") and trend_m.startswith("G"):
                                rating = 5 if volume_ok else 4
                            elif trend_s[:1] == trend_m[:1] and trend_s[:1] in ("T", "G"):
                                rating = 4
                            else:
                                rating = 3
                    except Exception:
                        rating = 3
                    
                    # ---- b·∫£o v·ªá sig_score ----
                    if sig_score is None:
                        sig_score = 0.0
                    
                    # ---- ghi ra sheet & l∆∞u candidate ----
                    now_vn = dt.datetime.now(pytz.timezone("Asia/Ho_Chi_Minh")).strftime("%d/%m/%Y %H:%M")
                    early_tag = " EARLY" if "[EARLY]" in str(reason) else ""
                    side_with_stars = f"{side}{early_tag} : ‚≠ê{max(1, min(int(rating), 5))}"
                    sheet_rows.append([symbol, side_with_stars, entry, sl, tp, trend_s, trend_m, now_vn, "RELAX"])
                    tg_candidates.append(("RELAX", symbol, f"{side}{early_tag}", entry, sl, tp, rating, sig_score))

        if ok:
            log_once("RELAX", symbol, f"[RELAX] {symbol}: ‚úÖ PASS", "info")
        else:
            log_once("RELAX", symbol, f"[RELAX] {symbol}: ‚ùå r·ªõt filter ‚Äì {reason}", "info")

    # ======= G·ªòP GHI GOOGLE SHEET M·ªòT L·∫¶N =======
    try:
        if sheet_rows:  # list c√°c d√≤ng ƒë√£ gom
            ws = client.open_by_key(sheet_id).worksheet("DATA_FUTURE")  # ƒë√∫ng t√™n sheet b·∫°n ƒëang d√πng
            prepend_with_retention(ws, sheet_rows, keep_days=3)
        else:
            logging.info("[SHEET] Kh√¥ng c√≥ d√≤ng n√†o ƒë·ªÉ ghi.")
    except Exception as e:
        logging.error(f"[SHEET] ghi batch l·ªói: {e}")

    # ===== G·ª¨I TELEGRAM 1 L·∫¶N  =====
    try:
        TOPN = TOPN_PER_BATCH  # nh·ªõ ƒë√£ khai b√°o bi·∫øn n√†y ·ªü ph·∫ßn CONFIG
    
        if tg_candidates:
            # Chu·∫©n ho√°: n·∫øu ph·∫ßn t·ª≠ ch∆∞a c√≥ score (7 ph·∫ßn t·ª≠) th√¨ g√°n score=0.0
            cand = []
            for t in tg_candidates:
                if len(t) == 8:
                    cand.append(t)  # (mode, sym, side, entry, sl, tp, rating, sig_score)
                else:
                    mode, sym, side, entry, sl, tp, rating = t
                    cand.append((mode, sym, side, entry, sl, tp, rating, sig_score))
    
            # S·∫Øp x·∫øp theo score gi·∫£m d·∫ßn v√† l·∫•y Top‚ÄëN
            cand.sort(key=lambda x: x[-1], reverse=True)
            pick = cand[:TOPN]
    
            # G·ªôp message ƒë·ªÉ g·ª≠i
            msgs = []
            for mode, sym, side, entry, sl, tp, rating, sc in pick:
                # Build message with size advice by mode
                size_advice = "Early 0.5√ó (scout)" if mode == "RELAX" else "ADD-ON/Full 1.0√ó"
                msgs.append(
                    f"[{mode}] | {sym} | {side}\n"
                    f"Entry: {entry}\nSL: {sl}\nTP: {tp}\n"
                    f"‚≠ê {rating}/5 | Score: {sc:.2f}\n"
                    f"Khuy·∫øn ngh·ªã: {size_advice}"
                )
    
            if msgs and 'send_telegram_message' in globals():
                send_telegram_message("üìå TOP t√≠n hi·ªáu m·∫°nh\n\n" + "\n\n".join(msgs))
                logging.info(f"[TG] ƒê√£ g·ª≠i {len(msgs)}/{len(cand)} t√≠n hi·ªáu (Top‚ÄëN).")
        else:
            logging.info("[TG] Kh√¥ng c√≥ t√≠n hi·ªáu n√†o ƒë·ªÉ g·ª≠i.")
    except Exception as e:
        logging.error(f"[TG] G·ª≠i Top‚ÄëN l·ªói: {e}")
    
def clean_old_rows():
    try:
        data = sheet.get_all_values()
        headers = data[0]
        rows = data[1:]
        today = dt.datetime.now(pytz.timezone("Asia/Ho_Chi_Minh")).date()

        new_rows = []
        for row in rows:
            try:
                row_date = dt.datetime.strptime(row[7], "%d/%m/%Y %H:%M").date()
                if (today - row_date).days < 3:
                    new_rows.append(row)
            except:
                new_rows.append(row)  # N·∫øu l·ªói parse date th√¨ gi·ªØ l·∫°i
        time.sleep(1)
        # Ghi l·∫°i: headers + rows m·ªõi
        sheet.clear()
        sheet.update([headers] + new_rows)
        logging.info(f"üßπ ƒê√£ xo√° nh·ªØng d√≤ng qu√° 3 ng√†y (gi·ªØ l·∫°i {len(new_rows)} d√≤ng)")

    except Exception as e:
        logging.warning(f"‚ùå L·ªói khi xo√° d√≤ng c≈©: {e}")

def get_top_usdt_pairs(limit=300):
    url = "https://www.okx.com/api/v5/public/instruments?instType=SPOT"
    try:
        res = requests.get(url)
        data = res.json()['data']
        usdt_pairs = [item['instId'] for item in data if item['quoteCcy'] == 'USDT']
        return usdt_pairs[:limit]
    except Exception as e:
        logging.error(f"L·ªói l·∫•y danh s√°ch coin: {e}")
        return []
if __name__ == "__main__":
    run_bot()

        
# ===== BACKTEST: ƒë·ªçc danh s√°ch t·ª´ sheet THEO D√ïI & ghi v·ªÅ BACKTEST_RESULT =====
# ==== PARSE & SHEET HELPERS (THEO D√ïI -> BACKTEST_RESULT) ====

def _to_user_entered(x):
    if x is None: return ""
    if isinstance(x, float):
        s = f"{x:.8f}".rstrip("0").rstrip(".")
        return s if s else "0"
    return str(x)

    
def _okx_inst_id(sym: str) -> str:
    s = sym.upper().replace("/", "-")
    return s if s.endswith("-SWAP") else s + "-SWAP"

def _ensure_timestamp_ms(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    if "timestamp" not in d.columns:
        ts = pd.to_numeric(d.index, errors="coerce")
        if ts.notna().all():
            # n·∫øu index ƒëang l√† gi√¢y th√¨ nh√¢n 1000 -> ms
            if ts.max() < 10**12:
                ts = ts * 1000.0
            d["timestamp"] = ts.astype("int64")
    if "timestamp" in d.columns:
        d = d.sort_values("timestamp").reset_index(drop=True)  # quan tr·ªçng: sort tƒÉng d·∫ßn
    return d
    
def _ensure_ts_col(df):
    """ƒê·∫£m b·∫£o c√≥ c·ªôt timestamp (ms) v√† sort tƒÉng d·∫ßn."""
    import pandas as pd, numpy as np
    if df is None or len(df) == 0:
        return df, None, None

    cols = [c.lower() for c in df.columns]
    df2 = df.copy()

    # OKX th∆∞·ªùng tr·∫£ 'ts' (ms). N·∫øu ch∆∞a c√≥ 'timestamp' th√¨ t·∫°o.
    if "timestamp" not in cols:
        if "ts" in df2.columns:
            df2["timestamp"] = pd.to_numeric(df2["ts"], errors="coerce")
        else:
            # th·ª≠ l·∫•y t·ª´ index
            try:
                ts = pd.to_numeric(df2.index, errors="coerce")
                if np.isfinite(ts).all():
                    df2["timestamp"] = ts
            except Exception:
                pass

    if "timestamp" not in [c.lower() for c in df2.columns]:
        return df2, None, None

    # sort theo th·ªùi gian tƒÉng d·∫ßn
    df2 = df2.sort_values(by=[col for col in df2.columns if col.lower()=="timestamp"][0])
    tmin = int(df2[[c for c in df2.columns if c.lower()=="timestamp"][0]].min())
    tmax = int(df2[[c for c in df2.columns if c.lower()=="timestamp"][0]].max())
    return df2, tmin, tmax


def _log_frame_span(tag, inst_id, when_utc, tmin, tmax):
    import datetime as dt, pytz
    def _fmt(ms):
        try:
            return dt.datetime.fromtimestamp(ms/1000, tz=pytz.utc).strftime("%Y-%m-%d %H:%M:%S%z")
        except Exception:
            return str(ms)
    if tmin is None:
        logging.debug(f"[BT] {tag} {inst_id}: ‚ùå kh√¥ng c√≥ c·ªôt timestamp.")
    else:
        logging.debug(
            f"[BT] {tag} {inst_id}: ts_entry={when_utc.strftime('%Y-%m-%d %H:%M:%S%z')} "
            f"| span=[{_fmt(tmin)} .. {_fmt(tmax)}]"
        )


def read_watchlist_from_sheet(sheet_name="THEO D√ïI"):
    """
    ƒê·ªçc sheet THEO D√ïI -> list tuple:
    (symbol, side, entry, sl, tp, trend_s, trend_m, when_vn, mode)
    """
    try:
        logging.info(f"[BACKTEST] üëâ m·ªü sheet '{sheet_name}' (id={sheet_id})")
        ws = client.open_by_key(sheet_id).worksheet(sheet_name)
    except Exception as e:
        logging.error(f"[BACKTEST] ‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c worksheet '{sheet_name}': {e}")
        return []

    try:
        rows = ws.get_all_values()
        logging.info(f"[BACKTEST] S·ªë d√≤ng ƒë·ªçc ƒë∆∞·ª£c (k·ªÉ c·∫£ header): {len(rows)}")
        if not rows or len(rows) < 2:
            logging.info("[BACKTEST] THEO D√ïI r·ªóng (kh√¥ng c√≥ d√≤ng d·ªØ li·ªáu d∆∞·ªõi header).")
            return []
    except Exception as e:
        logging.error(f"[BACKTEST] ‚ùå L·ªói get_all_values: {e}")
        return []

    # Header + map c·ªôt
    head = rows[0]
    logging.debug(f"[BACKTEST] Header: {head}")
    col = {name.strip(): i for i, name in enumerate(head)}
    logging.debug(f"[BACKTEST] Map c·ªôt: {col}")

    # Ki·ªÉm tra ƒë·ªß c·ªôt
    need = ["Coin","T√≠n hi·ªáu","Entry","SL","TP","Xu h∆∞·ªõng ng·∫Øn","Xu h∆∞·ªõng trung","Ng√†y","Mode"]
    missing = [n for n in need if n not in col]
    if missing:
        logging.warning(f"[BACKTEST] Thi·∫øu c·ªôt trong THEO D√ïI: {missing}")
        return []

    out = []
    parsed = 0

    for idx, r in enumerate(rows[1:] , start=2):  # b·∫Øt ƒë·∫ßu t·ª´ d√≤ng 2 (1-based)
        try:
            raw_when = (r[col["Ng√†y"]] or "").strip()
            when_vn  = parse_vn_time(raw_when)
            sym      = (r[col["Coin"]] or "").strip()
            side     = ((r[col["T√≠n hi·ªáu"]] or "").strip().split()[0]).upper()   # l·∫•y LONG/SHORT
            entry    = float(str(r[col["Entry"]]).replace(",", "")) if r[col["Entry"]] else None
            sl       = float(str(r[col["SL"]]).replace(",", ""))     if r[col["SL"]]    else None
            tp       = float(str(r[col["TP"]]).replace(",", ""))     if r[col["TP"]]    else None
            trend_s  = (r[col["Xu h∆∞·ªõng ng·∫Øn"]]  or "").strip()
            trend_m  = (r[col["Xu h∆∞·ªõng trung"]] or "").strip()
            mode     = (r[col["Mode"]] or "RELAX").strip().upper()

            # Log m·∫´u v√†i d√≤ng ƒë·∫ßu
            if idx <= 5:
                logging.debug(f"[BACKTEST] Row{idx}: sym={sym}, side={side}, entry={entry}, "
                              f"sl={sl}, tp={tp}, trend_s='{trend_s}', trend_m='{trend_m}', "
                              f"ng√†y='{raw_when}' -> when_vn={when_vn}, mode={mode}")

            # Validate t·ªëi thi·ªÉu
            if not sym or side not in ("LONG","SHORT") or when_vn is None:
                logging.warning(f"[BACKTEST] B·ªè d√≤ng {idx}: sym/side/ng√†y kh√¥ng h·ª£p l·ªá "
                                f"(sym='{sym}', side='{side}', raw_when='{raw_when}')")
                continue
            if entry is None or sl is None or tp is None:
                logging.warning(f"[BACKTEST] B·ªè d√≤ng {idx}: thi·∫øu Entry/SL/TP "
                                f"(entry={entry}, sl={sl}, tp={tp})")
                continue

            out.append((sym, side, entry, sl, tp, trend_s, trend_m, when_vn, mode))
            parsed += 1

        except Exception as e:
            logging.warning(f"[BACKTEST] L·ªói parse d√≤ng {idx}: {e} | raw={r}")

    logging.info(f"[BACKTEST] ‚úÖ Parse xong: {parsed} d√≤ng h·ª£p l·ªá / {len(rows)-1} d·ªØ li·ªáu.")
    return out


def write_backtest_row(row):
    """row = [Coin, T√≠n hi·ªáu, Entry, SL, TP, Xu h∆∞·ªõng ng·∫Øn, Xu h∆∞·ªõng trung, Ng√†y, Mode, K·∫øt qu·∫£]"""
    ws = client.open_by_key(sheet_id).worksheet("BACKTEST_RESULT")
    ws.append_row([_to_user_entered(x) for x in row], value_input_option="USER_ENTERED")
    time.sleep(1)


def ts_to_str(ms):
    """ms -> 'dd/MM/YYYY HH:MM' (UTC); tr·∫£ '‚Äî' n·∫øu None/l·ªói."""
    try:
        if ms is None or int(ms) <= 0:
            return "‚Äî"
        return datetime.fromtimestamp(int(ms)/1000, tz=timezone.utc).strftime("%d/%m/%Y %H:%M")
    except Exception:
        return "‚Äî"

def _first_touch_result(df, side, entry, sl, tp, sym=None, when_ts=None):
    """Quy t·∫Øc: n·∫øn n√†o ch·∫°m SL/TP tr∆∞·ªõc -> LOSS/WIN; h·∫øt c·ª≠a s·ªï m√† ch∆∞a ch·∫°m -> OPEN."""
    if df is None or len(df) == 0:
        if DEBUG_BACKTEST:
            logging.debug(f"[BT] {sym or ''} {side} -> OPEN (no candles)")
        return "OPEN"

    hit_logged = False
    for i, row in df.iterrows():
        try:
            h = float(row["high"]); l = float(row["low"])
            ts = int(row["timestamp"]) if "timestamp" in row else None
        except Exception:
            continue

        if side == "LONG":
            if l <= sl:
                if DEBUG_BACKTEST and not hit_logged:
                    logging.debug(f"[BT] {sym or ''} LONG -> LOSS at {ts_to_str(ts)} "
                                  f"(low={l:.6g} <= SL={sl:.6g})")
                    hit_logged = True
                return "LOSS"
            if h >= tp:
                if DEBUG_BACKTEST and not hit_logged:
                    logging.debug(f"[BT] {sym or ''} LONG -> WIN at {ts_to_str(ts)} "
                                  f"(high={h:.6g} >= TP={tp:.6g})")
                    hit_logged = True
                return "WIN"
        else:  # SHORT
            if h >= sl:
                if DEBUG_BACKTEST and not hit_logged:
                    logging.debug(f"[BT] {sym or ''} SHORT -> LOSS at {ts_to_str(ts)} "
                                  f"(high={h:.6g} >= SL={sl:.6g})")
                    hit_logged = True
                return "LOSS"
            if l <= tp:
                if DEBUG_BACKTEST and not hit_logged:
                    logging.debug(f"[BT] {sym or ''} SHORT -> WIN at {ts_to_str(ts)} "
                                  f"(low={l:.6g} <= TP={tp:.6g})")
                    hit_logged = True
                return "WIN"

    # Kh√¥ng ch·∫°m: log kho·∫£ng c√°ch g·∫ßn nh·∫•t ƒë·ªÉ bi·∫øt "v√¨ sao OPEN"
    if DEBUG_BACKTEST:
        try:
            import numpy as _np
            highs = _np.array(df["high"], dtype=float)
            lows  = _np.array(df["low"],  dtype=float)
            if side == "LONG":
                gap_sl = float(_np.min(_np.maximum(lows - sl, 0.0)))   # >=0
                gap_tp = float(_np.min(_np.maximum(tp - highs, 0.0))) # >=0
            else:
                gap_sl = float(_np.min(_np.maximum(highs - sl, 0.0)))
                gap_tp = float(_np.min(_np.maximum(lows - tp, 0.0)))
            t0 = _ts_to_str(int(df["timestamp"].iloc[0])) if "timestamp" in df.columns else "N/A"
            t1 = _ts_to_str(int(df["timestamp"].iloc[-1])) if "timestamp" in df.columns else "N/A"
            logging.debug(f"[BT] {sym or ''} {side} -> OPEN (no touch) | "
                          f"nearest gaps: SL={gap_sl:.6g}, TP={gap_tp:.6g} | "
                          f"window={t0}‚Üí{t1}, candles={len(df)}")
        except Exception:
            logging.debug(f"[BT] {sym or ''} {side} -> OPEN (no touch; gap calc failed)")
    return "OPEN"


def backtest_from_watchlist():
    """
    ƒê·ªçc sheet THEO D√ïI v√† ghi k·∫øt qu·∫£ v·ªÅ BACKTEST_RESULT.
    - timeframe: 15m
    - ch·ªâ ki·ªÉm tra n·∫øn c√≥ timestamp >= th·ªùi ƒëi·ªÉm t√≠n hi·ªáu
    - k·∫øt qu·∫£: WIN/LOSS/OPEN theo rule ch·∫°m SL/TP c√°i n√†o tr∆∞·ªõc
    """

    # --- util nh·ªè: key duy nh·∫•t cho 1 t√≠n hi·ªáu ---
    def _make_key(row):
        sym      = str(row[0]).strip().upper()
        side     = str(row[1]).split()[0].upper()      # b·ªè ph·∫ßn ‚≠ê
        entry    = f"{float(row[2]):.8f}"
        sl       = f"{float(row[3]):.8f}"
        tp       = f"{float(row[4]):.8f}"
        date_str = str(row[7]).strip()
        mode     = str(row[8]).strip().upper() if len(row) > 8 else ""
        return f"{sym}|{side}|{entry}|{sl}|{tp}|{date_str}|{mode}"

    # --- ƒë·ªçc THEO D√ïI ---
    items = read_watchlist_from_sheet("THEO D√ïI")  # tr·∫£ v·ªÅ list[list]
    if not items or len(items) <= 1:
        logging.info("[BACKTEST] THEO D√ïI r·ªóng (kh√¥ng c√≥ d√≤ng d·ªØ li·ªáu d∆∞·ªõi header).")
        return
    header = items[0]
    rows   = items[0:]  # b·ªè header

    logging.debug(f"[BACKTEST] Header: {header}")
    logging.info(f"[BACKTEST] üëç Parse xong: {len(rows)} d√≤ng h·ª£p l·ªá / {len(items)-1} d·ªØ li·ªáu.")

    # --- l·∫•y c√°c key ƒë√£ c√≥ ·ªü BACKTEST_RESULT ---
    existing_keys = set()
    try:
        rows_bt = read_watchlist_from_sheet("BACKTEST_RESULT")  # d√πng chung reader cho ƒë·ªìng nh·∫•t
        if rows_bt and len(rows_bt) > 1:
            for r in rows_bt[0:]:
                try:
                    k = _make_key(r)
                    existing_keys.add(k)
                except Exception:
                    continue
        logging.info(f"[BACKTEST] S·ªë key ƒëang c√≥ (BACKTEST_RESULT): {len(existing_keys)}")
    except Exception as e:
        logging.warning(f"[BACKTEST] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c BACKTEST_RESULT: {e}")

    # --- ch·∫°y backtest cho c√°c d√≤ng CH∆ØA c√≥ key ---
    seen_in_run = set()
    tf = "15m"
    max_after = 700
    written = 0

    for r in rows:
        try:
            if len(r) < 8:
                continue

            key = _make_key(r)
            if key in existing_keys or key in seen_in_run:
                # ƒë√£ c√≥ r·ªìi -> b·ªè qua
                continue

            sym  = str(r[0]).strip().upper()
            side = str(r[1]).split()[0].upper()
            entry = float(r[2]); sl = float(r[3]); tp = float(r[4])
            trend_s = str(r[5]).strip()
            trend_m = str(r[6]).strip()
            date_str = str(r[7]).strip()
            mode = str(r[8]).strip().upper() if len(r) > 8 else "RELAX"

            # th·ªùi ƒëi·ªÉm t√≠n hi·ªáu (VN) -> dt
            when_vn = parse_vn_time(date_str)  # b·∫°n ƒë√£ c√≥ h√†m n√†y
            if not when_vn:
                logging.warning(f"[BACKTEST] B·ªè {sym}: when_vn kh√¥ng h·ª£p l·ªá: {date_str}")
                continue

            # ƒë·ªïi VN -> UTC ms (OKX c·∫ßn UTC)
            when_utc = when_vn.astimezone(pytz.utc)
            bar_sec  = 15 * 60
            ts_floor = int((when_utc.timestamp() // bar_sec) * bar_sec)
            ts_cut   = ts_floor * 1000  # ms
            
            # chu·∫©n ho√° inst_id OKX
            inst_id = _okx_inst_id(sym)  # b·∫°n ƒë√£ c√≥ h√†m n√†y (upper + th√™m '-SWAP' n·∫øu thi·∫øu)

            # l·∫•y OHLCV 15m sau th·ªùi ƒëi·ªÉm t√≠n hi·ªáu 
            df = fetch_ohlcv_okx(inst_id, "15m", limit=1000)            

            if df is None or len(df) == 0:
                logging.debug(f"[BT] {sym} -> OPEN (no candles)")
                res = "OPEN"
            else:
                # ƒë·∫£m b·∫£o c√≥ c·ªôt timestamp (ms)
                if "timestamp" not in df.columns:
                    try:
                        ts = pd.to_numeric(df.index, errors="coerce")
                        if ts.notna().all():
                            if ts.max() < 10**12:   # gi√¢y -> ƒë·ªïi sang ms
                                ts = ts * 1000.0
                            df = df.copy()
                            df["timestamp"] = ts
                    except Exception:
                        pass

                # c·∫Øt ph·∫ßn sau t√≠n hi·ªáu
                logging.debug(f"[BACKTEST] {sym}: ts_cut={ts_cut}, t·ªïng n·∫øn={len(df)}, min_ts={df['timestamp'].min()}, max_ts={df['timestamp'].max()}")
                df_after = df[df["timestamp"] >= ts_cut] if "timestamp" in df.columns else df.copy()
                if df_after is None or len(df_after) == 0:
                    logging.warning(f"[BACKTEST] B·ªè {sym}: kh√¥ng c√≥ n·∫øn sau {when_vn} (ts_cut={ts_cut})")
                    continue
                if len(df_after) > max_after:
                    df_after = df_after.iloc[:max_after]
                res = _first_touch_result(df_after, side, entry, sl, tp)  # b·∫°n ƒë√£ c√≥ h√†m n√†y

            row_out = [
                sym, side, entry, sl, tp,
                trend_s, trend_m,
                when_vn.strftime("%d/%m/%Y %H:%M"),
                mode, res
            ]
            write_backtest_row(row_out)      # ghi 1 d√≤ng
            seen_in_run.add(key)
            written += 1
            time.sleep(1)

        except Exception as e:
            logging.warning(f"[BACKTEST] L·ªói v·ªõi {r}: {e}")

    logging.info(f"[BACKTEST] Ghi {written} d√≤ng v√†o sheet BACKTEST_RESULT xong.")


# ====== C·∫§U H√åNH ======
RUN_BACKTEST = True   # b·∫≠t ƒë·ªÉ ch·∫°y, t·∫Øt n·∫øu kh√¥ng c·∫ßn
if RUN_BACKTEST:
    logging.info("üöÄ B·∫Øt ƒë·∫ßu backtest t·ª´ sheet THEO D√ïI‚Ä¶")
    try:
        backtest_from_watchlist()
        logging.info("‚úÖ Ho√†n th√†nh backtest.")
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi backtest: {e}")
